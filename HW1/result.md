# Отчёт по домашнему заданию  
## Линейные модели и расширенный фичеинжиниринг

---

## Использование нейросети при выполнении работы

В процессе выполнения данного домашнего задания я использовал нейросеть (GPT-5) **не для решения за меня**, а для следующих строго ограниченных задач:

1. **Генерация словарей для категориальных признаков.**  
   Моих собственных знаний об автомобилях недостаточно, чтобы составить качественную нормализацию кузовов, трансмиссий и комплектаций. Поэтому словари (`body_type_dict`, `transmission_map`, `trim_levels`) были созданы с помощью нейросети.

2. **Автодополнение повторяющихся фрагментов кода.**  
   Чтобы не копировать большие однообразные блоки (например, выводы коэффициентов или форматированный print), использовал нейросеть для генерации аккуратного шаблона.

3. **Форматирование и оформление выводов.**  
   Использовал ИИ для создания читаемых, аккуратных и однородных текстовых отчётов в стиле консольных таблиц.

Во всех остальных частях (EDA, фичеинжиниринг, подбор гиперпараметров, обучение моделей, диагностика, исправления ошибок) работа была выполнена самостоятельно.

---

# Основные этапы работы

## 1. EDA

Выполнил стандартный расширенный EDA:

- привёл признаки к корректным типам;
- описал числовые признаки: статистики, пропуски, выбросы, асимметрии, эксцессы;
- описал текстовые признаки (в основном — столбец `name`);
- проверил корреляции (spearman, phik);
- визуализировал зависимости `selling_price` от ключевых признаков.

Все выводы и ответы на вопросы находятся в ноутбуке.

---

# 2. Модели, использованные в работе

## 2.1 Линейная регрессия (без нормализации)

**Метрики:**

R2 train   : 0.601128  

R2 test    : 0.600739  

MSE train  : 114332000615.76  

MSE test   : 229506671784.14  


---

## 2.2 Линейная регрессия (после нормализации)

Наиболее сильный признак: **max_power**  
Коэффициент: **331974.228042**

**Метрики:**

R2 train : 0.601128

R2 test  : 0.600739

---

## 2.3 Простая Lasso-регрессия

R2 train : 0.601128

R2 test  : 0.600738

Ни один коэффициент не занулился.

---

## 2.4 Lasso после GridSearchCV

Лучший alpha : 10000

Лучший max_iter : 1000

Лучший R2 (CV) : 0.580742

R2 train : 0.598380

R2 test  : 0.587076

Обнулились признаки:
- mileage  
- engine  
- seats  
- torque  

---

## 2.5 ElasticNet после GridSearchCV

Лучший alpha: 10000

Лучший l1_ratio: 1.0

Лучший fit_intercept: True

Лучший R2 (CV) : 0.580742

R2 train: 0.598380

R2 test : 0.587076

---

## 2.6 Самописная L0-регуляризация

Идея: обучаю обычную линейную модель и зануляю коэффициенты, модуль которых меньше порога `lambda_l0`.

lambda_l0 = 50000

R2 train : 0.591118

R2 test  : 0.573737

Обнулились почти все коэффициенты, кроме:  `year`, `max_power`, `max_torque_rpm`.

---

## 2.7 Ridge после GridSearchCV (базовая модель)

Лучший alpha : 1

Лучший R2 (CV) : 0.794039

R2 train : 0.897404

R2 test  : 0.923048

Результат значительно выше, чем у Lasso/ElasticNet.

---

## 2.8 Ridge моей обработки (бонусная улучшенная модель)

Лучший alpha : 1

Лучший R2 (CV) : 0.917357

R2 train : 0.930989

R2 test  : 0.946049

Эта модель оказалась **лучшей среди всех**.

# 3. Категориальные данные

Вся обработка категориальных данных сделана вручную:

- составлены словари нормализации (`body_type_dict`, `transmission_map`, `trim_levels`);
- написаны функции парсинга каждого типа;
- после получения новых фичей применён OneHotEncoding.
- заранее посмотрел на все слова, входящие в колонку `name` и извлек оттуда самые распространенные данные.
Из `name` были извлечены:
- кузов (`body_type`)
- трансмиссия (`parsed_transmission`)
- объём двигателя (`parsed_engine_volume`)
- комплектация (`parsed_trim`)
- марка (`mark`)
- модель (`model`)

# 4. Фичеинжиниринг (бонусная часть)

Вот перечень всех инженерных решений, которые были реализованы:

### Преобразование года в возраст автомобиля
age = 2020 - year (2020 поздний год выпуска автомобиля)
### Квадрат возраста
age_sq = age ** 2 (как рекомендовано было в описании)
### Признак количества владельцев
many_owners = owner in {3rd Owner, 4th & Above Owner}
### Логарифмирование таргета
Применено как рекомендованное улучшение модели:
log_price = log1p(selling_price)
### Умножение связанных признаков
Были созданы:
- power_engine = max_power * engine  
- power_age = max_power * age  
### Разделение seats на два столбца
- числовой  
- категориальный (для OHE)
### Target encoding (эксперимент)
Был проведён эксперимент:  

категории с количеством уникальных значений >20 кодировались через TargetEncoder.

Результат стал хуже, поэтому метод отключён и заменён на OneHotEncoding.

---

# 5. Бизнес-метрики

## 5.1 Business Metric
Показывает долю предсказаний, где ошибка ≤ 10%.

## 5.2 Student Metric
Показывает долю предсказаний, где ошибка > 30%.

Все таблицы метрик есть в ноутбуке.

---

# 6. Сохранение моделей в .pickle

Сохранено для **каждой модели**:

- сама модель;
- scaler (если использовался);
- encoder (если использовался);
- порядок признаков;
- список числовых и категориальных признаков;
- целевой признак (логарифмирован или нет).

Для каждой модели есть:

- отдельные файлы (model, scaler, encoder, meta)
- общий файл all_in_one.pkl  
  (для Streamlit, чтобы можно было загрузить одним объектом)

---

# 7. Итоговые выводы

### Самый большой прирост качества дали:
- фичеинжиниринг (age, age_sq, power_engine, power_age)
- логарифмирование таргета
- OneHot Encoding всех категорий
- Ridge Regression

### Лучшие модели по R²:
1. **Ridge моей обработки** — *R² test = 0.946049*  
2. **Базовый Ridge** — *R² test = 0.923048*  
3. Остальные линейные модели сильно уступают.

### Что не сработало:
- Target Encoding — ухудшил результаты.
- L0-регуляризация — слабее Ridge.
- Lasso / ElasticNet — слабые на этих данных.
- **Можно заметить**, что почему-то на train метрики хуже, чем на test. Это очень странная закономерность и требует дополнительного изучения. Мой первый вывод - что test имеет меньше данных, чем train и сильнее подвержен искажению метрики.

---

# 8. Общий вывод

В ходе работы была полностью реализована цепочка:

- глубокий EDA  
- строгая обработка данных  
- создание новых инженерных признаков  
- нормализация  
- OHE  
- обучение целой линейки линейных моделей  
- подбор гиперпараметров через GridSearch  
- реализация бизнес-метрик  
- создание полноценного набора pickle-файлов для продакшена  

Лучшие результаты достигаются тогда, когда:

1. фичи отражают реальные закономерности;
2. таргет стабилизирован логарифмированием;
3. используется Ridge-регрессия (как самая стабильная и устойчивая).


# UPDATE: 2 часть | Streamlit:

Во второй части я перешёл к реализации Streamlit-приложения. Сразу скажу, что я сделал его чуть шире, чем требовалось, потому что не всегда понятно, что именно подразумевалось в задании, а времени на перепроверку всех чатов, комментариев и апдейтов у меня сейчас просто нет. Поэтому я сделал так, чтобы приложение покрывало максимум возможных вариантов, даже если в итоге это было избыточно.

## 1) Структура проекта

- Папка **streamlit_app/** — здесь лежит основной файл `app.py`, в котором полностью реализован интерфейс.
- Папка **feature_engineering/** — отдельный модуль, в котором находится класс `MultiModelPipeline`, используемый именно для Streamlit. Имеет четыре режима EDA, base, medium, full в зависимости от задачи и модели.
Это позволяет приложению работать одинаково для всех моделей, независимо от того, как они были обучены.

## 2) Реализация EDA

Из-за того, что в задании не было понятно, какие именно данные использовать для EDA, я добавил сразу три варианта:

1. взять учебные данные **train**,  
2. взять учебные данные **test**,  
3. загрузить **свой CSV**.

По всем этим источникам строится одинаковый EDA.  
Сам EDA полностью повторяет тот, что у меня был в ноутбуке: scatterplot, histogram, KDE, pairplot, корреляционные матрицы, вывод первых строк и так далее. В том числе автоматически распарсивается `torque`, как и в первой части.  


## 3) Реализация инференса

Здесь я сделал по заданию, но с небольшой доработкой — так как не было сказано, какую модель использовать, я добавил выбор из всех 7 моделей, которые у меня получились в первой части.

Пользователь может:

- либо загрузить CSV,
- либо вручную ввести все параметры автомобиля (год, пробег, топливо, трансмиссия, владельцы, engine, max_power, torque, seats, name и т.д.).

После этого модель делает предсказание, а Streamlit показывает результат.

## 4) Веса моделей

Было задание визуализировать веса модели. Я сделал и график, и таблицу.

Но возник нюанс:

- у Ridge c OHE (модели 6) после OneHotEncoding получается больше 300 признаков,  
- encoder даёт имена вида `"0", "1", "2", …"`,
- поэтому ни один график нормально эти подписи не показывает.

У всех остальных моделей подписи нормальные.  
У Ridge c OHE подписи числовые, потому что так формируются названия колонок после OHE.

Я сделал график так, чтобы он автоматически растягивался под любое количество признаков, но выглядит это всё равно очень громоздко зато полностью честно отображает все веса модели.


## 5) Исправления после запуска Streamlit

Интересно, что некоторые ошибки в pkl-файлах я заметил только после запуска Streamlit, а не в ноутбуке:

- местами неправильно сохранялся `feature_order`,
- неправильно разделялись числовые и категориальные признаки.

Streamlit помог это найти, я поправил логику сохранения pkl и после этого все модели в приложении стали работать корректно. Надеюсь, что это не сильно повлияет на оценивание первой части.

## 6) Ссылка на Streamlit Cloud

https://hsemlhomeworks-dy7vukaps2nrjzrcxckmy7.streamlit.app





