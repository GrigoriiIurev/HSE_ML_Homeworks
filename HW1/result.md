# Отчёт по домашнему заданию  
## Линейные модели и расширенный фичеинжиниринг

---

## Использование нейросети при выполнении работы

В процессе выполнения данного домашнего задания я использовал нейросеть (GPT-5) **не для решения за меня**, а для следующих строго ограниченных задач:

1. **Генерация словарей для категориальных признаков.**  
   Моих собственных знаний об автомобилях недостаточно, чтобы составить качественную нормализацию кузовов, трансмиссий и комплектаций. Поэтому словари (`body_type_dict`, `transmission_map`, `trim_levels`) были созданы с помощью нейросети.

2. **Автодополнение повторяющихся фрагментов кода.**  
   Чтобы не копировать большие однообразные блоки (например, выводы коэффициентов или форматированный print), использовал нейросеть для генерации аккуратного шаблона.

3. **Форматирование и оформление выводов.**  
   Использовал ИИ для создания читаемых, аккуратных и однородных текстовых отчётов в стиле консольных таблиц.

Во всех остальных частях (EDA, фичеинжиниринг, подбор гиперпараметров, обучение моделей, диагностика, исправления ошибок) работа была выполнена самостоятельно.

---

# Основные этапы работы

## 1. EDA

Выполнил стандартный расширенный EDA:

- привёл признаки к корректным типам;
- описал числовые признаки: статистики, пропуски, выбросы, асимметрии, эксцессы;
- описал текстовые признаки (в основном — столбец `name`);
- проверил корреляции (spearman, phik);
- визуализировал зависимости `selling_price` от ключевых признаков.

Все выводы и ответы на вопросы находятся в ноутбуке.

---

# 2. Модели, использованные в работе

## 2.1 Линейная регрессия (без нормализации)

**Метрики:**

R2 train   : 0.601128  

R2 test    : 0.600739  

MSE train  : 114332000615.76  

MSE test   : 229506671784.14  


---

## 2.2 Линейная регрессия (после нормализации)

Наиболее сильный признак: **max_power**  
Коэффициент: **331974.228042**

**Метрики:**

R2 train : 0.601128
R2 test  : 0.600739

---

## 2.3 Простая Lasso-регрессия

R2 train : 0.601128
R2 test  : 0.600738

Ни один коэффициент не занулился.

---

## 2.4 Lasso после GridSearchCV

Лучший alpha : 10000
Лучший max_iter : 1000
Лучший R2 (CV) : 0.580742

R2 train : 0.598380
R2 test  : 0.587076

Обнулились признаки:
- mileage  
- engine  
- seats  
- torque  

---

## 2.5 ElasticNet после GridSearchCV

Лучший alpha: 10000
Лучший l1_ratio: 1.0
Лучший fit_intercept: True
Лучший R2 (CV) : 0.580742

R2 train: 0.598380
R2 test : 0.587076

---

## 2.6 Самописная L0-регуляризация

Идея: обучаю обычную линейную модель и зануляю коэффициенты, модуль которых меньше порога `lambda_l0`.

lambda_l0 = 50000

R2 train : 0.591118
R2 test  : 0.573737

Обнулились почти все коэффициенты, кроме:  
`year`, `max_power`, `max_torque_rpm`.

---

## 2.7 Ridge после GridSearchCV (базовая модель)

Лучший alpha : 1
Лучший R2 (CV) : 0.794039

R2 train : 0.897404
R2 test  : 0.923048

Результат значительно выше, чем у Lasso/ElasticNet.

---

## 2.8 Ridge моей обработки (бонусная улучшенная модель)

Лучший alpha : 1
Лучший R2 (CV) : 0.917357

R2 train : 0.930989
R2 test  : 0.946049

Эта модель оказалась **лучшей среди всех**.

# 3. Категориальные данные

Вся обработка категориальных данных сделана вручную:

- составлены словари нормализации (`body_type_dict`, `transmission_map`, `trim_levels`);
- написаны функции парсинга каждого типа;
- после получения новых фичей применён OneHotEncoding.
- заранее посмотрел на все слова, входящие в колонку `name` и извлек оттуда самые распространенные данные.
Из `name` были извлечены:
- кузов (`body_type`)
- трансмиссия (`parsed_transmission`)
- объём двигателя (`parsed_engine_volume`)
- комплектация (`parsed_trim`)
- марка (`mark`)
- модель (`model`)

# 4. Фичеинжиниринг (бонусная часть)

Вот перечень всех инженерных решений, которые были реализованы:

### ✔ Преобразование года в возраст автомобиля
age = 2020 - year (2020 поздний год выпуска автомобиля)
### ✔ Квадрат возраста
age_sq = age ** 2 (как рекомендовано было в описании)
### ✔ Признак количества владельцев
many_owners = owner in {3rd Owner, 4th & Above Owner}
### ✔ Логарифмирование таргета
Применено как рекомендованное улучшение модели:
log_price = log1p(selling_price)
### ✔ Умножение связанных признаков
Были созданы:
- power_engine = max_power * engine  
- power_age = max_power * age  
### ✔ Разделение seats на два столбца
- числовой  
- категориальный (для OHE)
### ✔ Target encoding (эксперимент)
Был проведён эксперимент:  
категории с количеством уникальных значений >20 кодировались через TargetEncoder.

Результат стал хуже, поэтому метод отключён и заменён на OneHotEncoding.

---

# 5. Бизнес-метрики

## 5.1 Business Metric
Показывает долю предсказаний, где ошибка ≤ 10%.

## 5.2 Student Metric
Показывает долю предсказаний, где ошибка > 30%.

Все таблицы метрик есть в ноутбуке.

---

# 6. Сохранение моделей в .pickle

Сохранено для **каждой модели**:

- сама модель;
- scaler (если использовался);
- encoder (если использовался);
- порядок признаков;
- список числовых и категориальных признаков;
- целевой признак (логарифмирован или нет).

Для каждой модели есть:

- отдельные файлы (model, scaler, encoder, meta)
- общий файл all_in_one.pkl  
  (для Streamlit, чтобы можно было загрузить одним объектом)

---

# 7. Итоговые выводы

### Самый большой прирост качества дали:
- фичеинжиниринг (age, age_sq, power_engine, power_age)
- логарифмирование таргета
- OneHot Encoding всех категорий
- Ridge Regression

### Лучшие модели по R²:
1. **Ridge моей обработки** — *R² test = 0.946049*  
2. **Базовый Ridge** — *R² test = 0.923048*  
3. Остальные линейные модели сильно уступают.

### Что не сработало:
- Target Encoding — ухудшил результаты.
- L0-регуляризация — слабее Ridge.
- Lasso / ElasticNet — слабые на этих данных.
- **Можно заметить**, что почему-то на train метрики хуже, чем на test. Это очень странная закономерность и требует дополнительного изучения. Мой первый вывод - что test имеет меньше данных, чем train и сильнее подвержен искажению метрики.

---

# 8. Общий вывод

В ходе работы была полностью реализована цепочка:

- глубокий EDA  
- строгая обработка данных  
- создание новых инженерных признаков  
- нормализация  
- OHE  
- обучение целой линейки линейных моделей  
- подбор гиперпараметров через GridSearch  
- реализация бизнес-метрик  
- создание полноценного набора pickle-файлов для продакшена  

Лучшие результаты достигаются тогда, когда:

1. фичи отражают реальные закономерности;
2. таргет стабилизирован логарифмированием;
3. используется Ridge-регрессия (как самая стабильная и устойчивая).

Работа выполнена полностью, все вопросы из задания отражены в ноутбуке.





